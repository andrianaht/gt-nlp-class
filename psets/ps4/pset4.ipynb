{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem Set 4: Sequence labeling\n",
    "=====================\n",
    "\n",
    "This project focuses on sequence labeling, in the target domain of Twitter part-of-speech tagging.\n",
    "Part (b) focuses on *discriminative* approaches, mainly averaged perceptron and structured perceptron.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Submission guidelines:###\n",
    "\n",
    "Here are some submission guidelines for the problem set submission on t-square. Please try to adhere to them as it makes grading simpler.\n",
    "\n",
    "* Submit these 3 things on tsquare: \n",
    "\n",
    "   * compressed gtnlplib folder containing all your code. Please don't attach all python files separately to t-square. \n",
    "    \n",
    "   * pset4.ipynb to present all your explanation answers and results.\n",
    "    \n",
    "   * There will be multiple response files that will be generated throughout the assignment. 4 for your normal models on dev data and 1 for bake off on test data. Use createSubmission.sh script to compress these files and submit the generated response_files.tar on Tsquare.\n",
    "\n",
    "\n",
    "   * For 'Error Analysis' part write your answers in the notebook only. If you want to point to any code/functions that you have written separately, please point the location of code in the notebook file.\n",
    "\n",
    "* Please don't modify any of the relative paths to data. You can copy the 'data' folder according to the given relatove path in the 'gtnlplib/constants.py' while working through the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab --no-import-all inline\n",
    "\n",
    "import gtnlplib.preproc\n",
    "import gtnlplib.viterbi\n",
    "import gtnlplib.clf_base\n",
    "import gtnlplib.scorer\n",
    "import gtnlplib.constants\n",
    "import gtnlplib.features\n",
    "import gtnlplib.tagger_base\n",
    "import gtnlplib.avg_perceptron\n",
    "import gtnlplib.str_perceptron\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.preproc' from 'gtnlplib/preproc.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define the file names\n",
    "trainfile = gtnlplib.constants.TRAIN_FILE\n",
    "devfile = gtnlplib.constants.DEV_FILE\n",
    "testfile = gtnlplib.constants.TEST_FILE # You do not have this for now\n",
    "offset = gtnlplib.constants.OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for convenience\n",
    "tr_all = []\n",
    "for i,(words,tags) in enumerate(gtnlplib.preproc.conllSeqGenerator(trainfile)):\n",
    "    tr_all.append((words,tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['!', '#', '$', '&', ',', 'A', '@', 'E', 'D', 'G', 'M', 'L', 'O', 'N', 'P', 'S', 'R', 'U', 'T', 'V', 'Y', 'X', 'Z', '^', '~'])\n"
     ]
    }
   ],
   "source": [
    "## Demo\n",
    "alltags = set()\n",
    "for i,(words, tags) in enumerate(gtnlplib.preproc.conllSeqGenerator(trainfile)):    \n",
    "    for tag in tags:\n",
    "        alltags.add(tag)\n",
    "print alltags\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Classification-based tagging #\n",
    "\n",
    "First, you will perform tagging as classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in structured prediction, we have the feature function decompose:\n",
    "\n",
    "\\begin{align}\n",
    "\\renewcommand{\\vec}[1]{\\mathbf{#1}}\n",
    "\\vec{f}(\\vec{w},\\vec{y}) & = \\sum_m \\vec{f}(\\vec{w},y_m, y_{m-1}, m)\n",
    "\\end{align}\n",
    "\n",
    "You will explicitly define your feature functions in this way -- even for the classification-based tagger, which won't consider $y_{m-1}$. The features themselves are defined as tuples, as in pset 3.\n",
    "\n",
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordFeatures(words,tag,prev_tag,m):\n",
    "    '''\n",
    "    :param words: a list of words\n",
    "    :type words: list\n",
    "    :param tag: a tag\n",
    "    :type tag: string\n",
    "    :type prev_tag: string\n",
    "    :type m: int\n",
    "    '''\n",
    "    out = {(offset,tag):1}\n",
    "    if m < len(words): #we can have m = M, for the transition to the end state\n",
    "        out[(gtnlplib.constants.EMIT,tag,words[m])]=1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = 'they can can fish'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('**OFFSET**', 'V'): 1, ('--EMISSION--', 'V', 'they'): 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print wordFeatures(sent,'V','N',4)\n",
    "# print wordFeatures(sent,'V','X',0)\n",
    "wordFeatures(sent,'V','V',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1a** (1 point) Complete feature function 'wordCharFeatures' in gtnlplib/features.py, which includes the final character of the current word, and the final character of the preceding word (if $m > 1$) along with above features. The names for these features are defined in gtnlplib.constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.features' from 'gtnlplib/features.pyc'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('--curr-suff--', 'V', 'n'): 1, ('--EMISSION--', 'V', 'can'): 1, ('**OFFSET**', 'V'): 1, ('--prev-suff--', 'V', 'y'): 1}\n",
      "{('--curr-suff--', 'V', 'y'): 1, ('**OFFSET**', 'V'): 1, ('--EMISSION--', 'V', 'they'): 1}\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.features)\n",
    "# sanity check desired output\n",
    "print gtnlplib.features.wordCharFeatures(sent,'V','V',1)\n",
    "# no prev-suff feature in this one, because m=0\n",
    "print gtnlplib.features.wordCharFeatures(sent,'V','V',0)\n",
    "\n",
    "# 'they can can fish'\n",
    "# print gtnlplib.features.wordCharFeatures(sent,'V','V', 3)\n",
    "# print gtnlplib.features.wordCharFeatures(sent,'N','V', 3)\n",
    "# print gtnlplib.features.wordCharFeatures(sent, gtnlplib.constants.END_TAG,'N', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will define a classification-based tagger. To get you started, here are some test weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'float'>, {('--EMISSION--', 'X', 'fish'): 1, ('--EMISSION--', 'N', 'fish'): 1, ('--EMISSION--', 'X', 'they'): 1, ('--EMISSION--', 'V', 'can'): 1, ('**OFFSET**', 'V'): 1, ('--EMISSION--', 'N', 'they'): 1, ('**OFFSET**', 'N'): 1, ('--EMISSION--', 'X', 'can'): 1, ('**OFFSET**', 'X'): 1})\n"
     ]
    }
   ],
   "source": [
    "test_weights = defaultdict(float)\n",
    "test_tags = ['N','V','V','N']\n",
    "for i in range(len(sent)):\n",
    "    for feat in wordFeatures(sent,test_tags[i],'X',i):\n",
    "        test_weights[feat] = 1\n",
    "    for feat in wordFeatures(sent,'X','X',i):\n",
    "        test_weights[feat] = 1\n",
    "print test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use this to find the highest-scoring label\n",
    "argmax = lambda x : max(x.iteritems(),key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1b** (1 point): Complete the function classifierTagger in gtnlplib/tagger_base.py that takes a list of words, feature function, dict of weights, and a tagset, and outputs a list of predicted tags (one per word).\n",
    "\n",
    "You should use featfunc to get the features and return the list of tags with highest score for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N', 'V', 'V', 'N']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.tagger_base)\n",
    "gtnlplib.tagger_base.classifierTagger(sent,wordFeatures,test_weights,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.139539705577\n"
     ]
    }
   ],
   "source": [
    "confusion = gtnlplib.tagger_base.evalTagger(lambda words,alltags : gtnlplib.tagger_base.classifierTagger(words,wordFeatures,test_weights,alltags),'test')\n",
    "print gtnlplib.scorer.accuracy(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Deliverable 1c** (3 points): Apply your averaged perceptron from pset 2 to do part-of-speech tagging. Start by adapting your oneItAvgPerceptron function. You'll have to make some changes:\n",
    "\n",
    "- Replace your call to the predict() function with a call to classifierTagger()\n",
    "- The instanceGenerator now produces word lists and tag lists as instances, instead of feature counts.\n",
    "- You can treat entire sentences as instances, if you want -- this may be slightly easier. This means that you only update the weights after seeing an entire sentence, sort of like a minibatch.\n",
    "- You'll want to add the feature function as an extra argument to both oneItAvgPerceptron and trainAvgPerceptron\n",
    "- return the training accuracy rather than the number of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete oneItAvgPerceptron function from gtnlplib/avg_perceptron.py for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.avg_perceptron' from 'gtnlplib/avg_perceptron.pyc'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.avg_perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.avg_perceptron)\n",
    "reload(gtnlplib.features)\n",
    "reload(gtnlplib.tagger_base)\n",
    "weights,wsum,tr_acc,i = gtnlplib.avg_perceptron.oneItAvgPerceptron(tr_all,wordFeatures,defaultdict(float),defaultdict(float),alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.0 2611.0\n",
      "-1.0 -212.0\n",
      "2.0 587.0\n",
      "5.0 942.0\n"
     ]
    }
   ],
   "source": [
    "#sanity check. The weight sum numbers might be different if you don't treat sentences as instances, which is what I do.\n",
    "print weights[gtnlplib.constants.EMIT,'D','the'], wsum[gtnlplib.constants.EMIT,'D','the']\n",
    "print weights[gtnlplib.constants.EMIT,'N','the'], wsum[gtnlplib.constants.EMIT,'N','the']\n",
    "print weights[gtnlplib.constants.EMIT,'V','like'], wsum[gtnlplib.constants.EMIT,'V','like']\n",
    "print weights[gtnlplib.constants.EMIT,'P','like'], wsum[gtnlplib.constants.EMIT,'P','like']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1d** (2 points): Now adapt trainAvgPerceptron function in gtnlplib/avg_perceptron.py to do tagging. This should require fewer changes than oneItAvgPerceptron, but you will have to:\n",
    "\n",
    "- take a feature function as an argument\n",
    "- call evalTagger instead of evalClassifier to get the confusion matrix\n",
    "- don't forget you've modified oneItAvgPerceptron to return the training set accuracy, not the number of errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.673439767779 train: 0.523428415076\n",
      "1 dev: 0.710346257516 train: 0.685477802859\n",
      "2 dev: 0.729836201534 train: 0.764279362473\n",
      "3 dev: 0.736678415924 train: 0.824953827211\n",
      "4 dev: 0.742691270993 train: 0.853615158356\n",
      "5 dev: 0.746423387933 train: 0.879813940762\n",
      "6 dev: 0.746423387933 train: 0.89034817703\n",
      "7 dev: 0.746630727763 train: 0.899445926534\n",
      "8 dev: 0.747045407423 train: 0.903892195089\n",
      "9 dev: 0.747460087083 train: 0.904713044668\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.avg_perceptron)\n",
    "reload(gtnlplib.features)\n",
    "reload(gtnlplib.tagger_base)\n",
    "w, tr_acc, dv_acc =  gtnlplib.avg_perceptron.trainAvgPerceptron(10,tr_all,gtnlplib.features.wordCharFeatures,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('!', '!'): 52,\n",
       "             ('!', ','): 2,\n",
       "             ('!', '@'): 1,\n",
       "             ('!', 'D'): 2,\n",
       "             ('!', 'N'): 19,\n",
       "             ('!', 'O'): 3,\n",
       "             ('!', 'R'): 2,\n",
       "             ('!', 'U'): 6,\n",
       "             ('!', 'V'): 3,\n",
       "             ('!', '^'): 9,\n",
       "             ('#', '!'): 1,\n",
       "             ('#', '#'): 5,\n",
       "             ('#', '@'): 8,\n",
       "             ('#', 'N'): 14,\n",
       "             ('#', 'R'): 1,\n",
       "             ('#', 'U'): 3,\n",
       "             ('#', 'V'): 15,\n",
       "             ('#', '^'): 5,\n",
       "             ('$', '!'): 1,\n",
       "             ('$', '$'): 51,\n",
       "             ('$', '@'): 5,\n",
       "             ('$', 'A'): 1,\n",
       "             ('$', 'N'): 3,\n",
       "             ('$', 'O'): 1,\n",
       "             ('$', 'P'): 5,\n",
       "             ('$', 'U'): 10,\n",
       "             ('$', 'V'): 2,\n",
       "             ('$', '^'): 6,\n",
       "             ('$', '~'): 1,\n",
       "             ('&', '&'): 87,\n",
       "             ('&', 'D'): 2,\n",
       "             ('&', 'R'): 1,\n",
       "             ('&', 'Z'): 1,\n",
       "             (',', ','): 459,\n",
       "             (',', '@'): 1,\n",
       "             (',', 'E'): 2,\n",
       "             (',', 'G'): 1,\n",
       "             (',', '~'): 37,\n",
       "             ('@', '$'): 5,\n",
       "             ('@', '@'): 153,\n",
       "             ('@', 'E'): 2,\n",
       "             ('@', 'G'): 1,\n",
       "             ('@', 'N'): 27,\n",
       "             ('@', 'O'): 2,\n",
       "             ('@', 'P'): 1,\n",
       "             ('@', 'R'): 1,\n",
       "             ('@', 'U'): 6,\n",
       "             ('@', 'V'): 29,\n",
       "             ('@', 'Z'): 2,\n",
       "             ('@', '^'): 14,\n",
       "             ('A', '!'): 2,\n",
       "             ('A', '$'): 1,\n",
       "             ('A', '@'): 4,\n",
       "             ('A', 'A'): 112,\n",
       "             ('A', 'N'): 58,\n",
       "             ('A', 'O'): 2,\n",
       "             ('A', 'P'): 1,\n",
       "             ('A', 'R'): 11,\n",
       "             ('A', 'T'): 1,\n",
       "             ('A', 'U'): 3,\n",
       "             ('A', 'V'): 36,\n",
       "             ('A', '^'): 8,\n",
       "             ('D', '!'): 3,\n",
       "             ('D', '@'): 2,\n",
       "             ('D', 'D'): 288,\n",
       "             ('D', 'G'): 1,\n",
       "             ('D', 'L'): 3,\n",
       "             ('D', 'N'): 7,\n",
       "             ('D', 'P'): 4,\n",
       "             ('D', 'R'): 1,\n",
       "             ('D', 'V'): 1,\n",
       "             ('D', '^'): 2,\n",
       "             ('E', '$'): 2,\n",
       "             ('E', ','): 3,\n",
       "             ('E', 'E'): 34,\n",
       "             ('E', 'G'): 1,\n",
       "             ('E', 'N'): 1,\n",
       "             ('E', 'U'): 3,\n",
       "             ('E', 'V'): 2,\n",
       "             ('E', '^'): 2,\n",
       "             ('E', '~'): 4,\n",
       "             ('G', ','): 12,\n",
       "             ('G', '@'): 1,\n",
       "             ('G', 'E'): 1,\n",
       "             ('G', 'G'): 18,\n",
       "             ('G', 'N'): 10,\n",
       "             ('G', 'O'): 4,\n",
       "             ('G', 'P'): 1,\n",
       "             ('G', 'R'): 1,\n",
       "             ('G', 'U'): 4,\n",
       "             ('G', 'V'): 6,\n",
       "             ('G', '^'): 3,\n",
       "             ('G', '~'): 4,\n",
       "             ('L', 'D'): 2,\n",
       "             ('L', 'L'): 46,\n",
       "             ('L', 'N'): 8,\n",
       "             ('L', 'U'): 1,\n",
       "             ('L', 'V'): 5,\n",
       "             ('L', '^'): 3,\n",
       "             ('N', '!'): 4,\n",
       "             ('N', '$'): 2,\n",
       "             ('N', '&'): 1,\n",
       "             ('N', ','): 1,\n",
       "             ('N', '@'): 6,\n",
       "             ('N', 'A'): 4,\n",
       "             ('N', 'E'): 5,\n",
       "             ('N', 'G'): 4,\n",
       "             ('N', 'N'): 508,\n",
       "             ('N', 'O'): 1,\n",
       "             ('N', 'P'): 5,\n",
       "             ('N', 'R'): 8,\n",
       "             ('N', 'U'): 6,\n",
       "             ('N', 'V'): 73,\n",
       "             ('N', '^'): 31,\n",
       "             ('N', '~'): 1,\n",
       "             ('O', '$'): 1,\n",
       "             ('O', '@'): 1,\n",
       "             ('O', 'D'): 12,\n",
       "             ('O', 'N'): 4,\n",
       "             ('O', 'O'): 304,\n",
       "             ('O', 'P'): 8,\n",
       "             ('O', 'V'): 1,\n",
       "             ('O', '^'): 2,\n",
       "             ('P', '$'): 2,\n",
       "             ('P', 'A'): 3,\n",
       "             ('P', 'D'): 1,\n",
       "             ('P', 'N'): 7,\n",
       "             ('P', 'P'): 411,\n",
       "             ('P', 'R'): 5,\n",
       "             ('P', 'T'): 5,\n",
       "             ('P', 'U'): 1,\n",
       "             ('P', 'V'): 4,\n",
       "             ('P', '^'): 1,\n",
       "             ('R', '!'): 2,\n",
       "             ('R', '&'): 1,\n",
       "             ('R', '@'): 2,\n",
       "             ('R', 'A'): 17,\n",
       "             ('R', 'D'): 2,\n",
       "             ('R', 'N'): 19,\n",
       "             ('R', 'P'): 13,\n",
       "             ('R', 'R'): 142,\n",
       "             ('R', 'S'): 1,\n",
       "             ('R', 'T'): 2,\n",
       "             ('R', 'V'): 6,\n",
       "             ('R', '^'): 2,\n",
       "             ('S', '@'): 1,\n",
       "             ('S', 'N'): 4,\n",
       "             ('T', 'N'): 1,\n",
       "             ('T', 'O'): 1,\n",
       "             ('T', 'P'): 4,\n",
       "             ('T', 'R'): 1,\n",
       "             ('T', 'T'): 29,\n",
       "             ('U', '$'): 6,\n",
       "             ('U', ','): 1,\n",
       "             ('U', '@'): 2,\n",
       "             ('U', 'E'): 1,\n",
       "             ('U', 'G'): 2,\n",
       "             ('U', 'N'): 14,\n",
       "             ('U', 'P'): 1,\n",
       "             ('U', 'U'): 39,\n",
       "             ('U', 'V'): 11,\n",
       "             ('U', '^'): 13,\n",
       "             ('U', '~'): 1,\n",
       "             ('V', '!'): 1,\n",
       "             ('V', ','): 1,\n",
       "             ('V', '@'): 16,\n",
       "             ('V', 'A'): 5,\n",
       "             ('V', 'E'): 1,\n",
       "             ('V', 'G'): 1,\n",
       "             ('V', 'N'): 67,\n",
       "             ('V', 'P'): 5,\n",
       "             ('V', 'R'): 2,\n",
       "             ('V', 'U'): 6,\n",
       "             ('V', 'V'): 635,\n",
       "             ('V', '^'): 7,\n",
       "             ('V', '~'): 4,\n",
       "             ('X', 'O'): 1,\n",
       "             ('X', 'R'): 2,\n",
       "             ('X', 'X'): 1,\n",
       "             ('Z', 'N'): 6,\n",
       "             ('Z', 'V'): 3,\n",
       "             ('^', '!'): 1,\n",
       "             ('^', '$'): 2,\n",
       "             ('^', ','): 1,\n",
       "             ('^', '@'): 29,\n",
       "             ('^', 'A'): 3,\n",
       "             ('^', 'D'): 2,\n",
       "             ('^', 'G'): 4,\n",
       "             ('^', 'N'): 118,\n",
       "             ('^', 'O'): 2,\n",
       "             ('^', 'P'): 1,\n",
       "             ('^', 'R'): 7,\n",
       "             ('^', 'U'): 13,\n",
       "             ('^', 'V'): 40,\n",
       "             ('^', '^'): 88,\n",
       "             ('~', ','): 27,\n",
       "             ('~', '~'): 143})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You will get the test file later (48 hours before the deadline)\n",
    "gtnlplib.tagger_base.evalTagger(lambda words,alltags : gtnlplib.tagger_base.classifierTagger(words,gtnlplib.features.wordCharFeatures,w,alltags),'avg_perceptron.response',testfile=devfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 1e** (3 points): Make it better! Design a killer feature set that improves performance on the devset.\n",
    "\n",
    "I'm able to get above 84% on the dev set, without going too crazy. Warning: my additional features slow things down considerably.\n",
    "\n",
    "\n",
    "Please complete yourFeatures function from gtnlplib/features.py for this.\n",
    "In order to pass unit tests for this you should be able to get at least 81%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.features' from 'gtnlplib/features.py'>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.constants)\n",
    "reload(gtnlplib.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.812357453867 train: 0.685614611123\n",
      "1 dev: 0.831847397885 train: 0.851152609618\n",
      "2 dev: 0.838482272445 train: 0.907449209932\n",
      "3 dev: 0.841177690234 train: 0.933169163417\n",
      "4 dev: 0.844909807174 train: 0.947055202134\n",
      "5 dev: 0.848641924114 train: 0.959504754087\n",
      "6 dev: 0.850507982583 train: 0.963540597852\n",
      "7 dev: 0.847605224964 train: 0.971612285382\n",
      "8 dev: 0.846361185984 train: 0.977837061359\n",
      "9 dev: 0.848227244454 train: 0.979957589438\n",
      "10 dev: 0.846775865644 train: 0.982488542308\n",
      "11 dev: 0.845531826664 train: 0.983651412545\n",
      "12 dev: 0.847190545304 train: 0.985840344757\n",
      "13 dev: 0.845531826664 train: 0.988302893495\n",
      "14 dev: 0.844702467344 train: 0.989328955469\n"
     ]
    }
   ],
   "source": [
    "w, tr_acc, dv_acc = gtnlplib.avg_perceptron.trainAvgPerceptron(15,tr_all,gtnlplib.features.yourFeatures,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('!', '!'): 70,\n",
       "             ('!', ','): 2,\n",
       "             ('!', 'D'): 2,\n",
       "             ('!', 'G'): 1,\n",
       "             ('!', 'N'): 10,\n",
       "             ('!', 'R'): 1,\n",
       "             ('!', 'V'): 2,\n",
       "             ('!', '^'): 11,\n",
       "             ('#', '#'): 42,\n",
       "             ('#', 'N'): 2,\n",
       "             ('#', 'V'): 1,\n",
       "             ('#', '^'): 7,\n",
       "             ('$', '#'): 2,\n",
       "             ('$', '$'): 63,\n",
       "             ('$', ','): 2,\n",
       "             ('$', 'A'): 1,\n",
       "             ('$', 'N'): 6,\n",
       "             ('$', 'O'): 1,\n",
       "             ('$', 'P'): 5,\n",
       "             ('$', 'V'): 2,\n",
       "             ('$', '^'): 4,\n",
       "             ('&', '&'): 86,\n",
       "             ('&', ','): 1,\n",
       "             ('&', 'D'): 1,\n",
       "             ('&', 'P'): 2,\n",
       "             ('&', 'V'): 1,\n",
       "             (',', ','): 491,\n",
       "             (',', 'E'): 1,\n",
       "             (',', 'P'): 1,\n",
       "             (',', 'U'): 1,\n",
       "             (',', '~'): 6,\n",
       "             ('@', '@'): 243,\n",
       "             ('A', '!'): 2,\n",
       "             ('A', '$'): 1,\n",
       "             ('A', 'A'): 149,\n",
       "             ('A', 'D'): 1,\n",
       "             ('A', 'N'): 33,\n",
       "             ('A', 'O'): 2,\n",
       "             ('A', 'P'): 1,\n",
       "             ('A', 'R'): 5,\n",
       "             ('A', 'T'): 1,\n",
       "             ('A', 'V'): 30,\n",
       "             ('A', '^'): 14,\n",
       "             ('D', '!'): 4,\n",
       "             ('D', 'D'): 286,\n",
       "             ('D', 'G'): 1,\n",
       "             ('D', 'L'): 2,\n",
       "             ('D', 'N'): 2,\n",
       "             ('D', 'O'): 4,\n",
       "             ('D', 'P'): 1,\n",
       "             ('D', 'R'): 2,\n",
       "             ('D', 'V'): 2,\n",
       "             ('D', 'X'): 5,\n",
       "             ('D', '^'): 3,\n",
       "             ('E', '$'): 2,\n",
       "             ('E', ','): 6,\n",
       "             ('E', 'E'): 40,\n",
       "             ('E', 'G'): 1,\n",
       "             ('E', 'U'): 1,\n",
       "             ('E', '^'): 1,\n",
       "             ('E', '~'): 1,\n",
       "             ('G', '!'): 3,\n",
       "             ('G', '#'): 3,\n",
       "             ('G', '$'): 1,\n",
       "             ('G', ','): 13,\n",
       "             ('G', 'A'): 1,\n",
       "             ('G', 'D'): 2,\n",
       "             ('G', 'E'): 4,\n",
       "             ('G', 'G'): 20,\n",
       "             ('G', 'L'): 1,\n",
       "             ('G', 'N'): 5,\n",
       "             ('G', 'O'): 1,\n",
       "             ('G', 'P'): 2,\n",
       "             ('G', 'R'): 2,\n",
       "             ('G', 'V'): 2,\n",
       "             ('G', '^'): 4,\n",
       "             ('G', '~'): 1,\n",
       "             ('L', 'D'): 2,\n",
       "             ('L', 'L'): 55,\n",
       "             ('L', 'N'): 2,\n",
       "             ('L', 'O'): 1,\n",
       "             ('L', 'V'): 4,\n",
       "             ('L', 'Z'): 1,\n",
       "             ('N', '!'): 3,\n",
       "             ('N', '#'): 5,\n",
       "             ('N', '$'): 4,\n",
       "             ('N', '@'): 1,\n",
       "             ('N', 'A'): 16,\n",
       "             ('N', 'E'): 3,\n",
       "             ('N', 'G'): 2,\n",
       "             ('N', 'L'): 3,\n",
       "             ('N', 'N'): 539,\n",
       "             ('N', 'O'): 3,\n",
       "             ('N', 'P'): 4,\n",
       "             ('N', 'R'): 10,\n",
       "             ('N', 'V'): 36,\n",
       "             ('N', 'Z'): 1,\n",
       "             ('N', '^'): 29,\n",
       "             ('N', '~'): 1,\n",
       "             ('O', '!'): 1,\n",
       "             ('O', 'D'): 6,\n",
       "             ('O', 'N'): 3,\n",
       "             ('O', 'O'): 317,\n",
       "             ('O', 'P'): 4,\n",
       "             ('O', 'R'): 1,\n",
       "             ('O', 'V'): 1,\n",
       "             ('P', '$'): 1,\n",
       "             ('P', 'A'): 1,\n",
       "             ('P', 'D'): 2,\n",
       "             ('P', 'N'): 6,\n",
       "             ('P', 'O'): 4,\n",
       "             ('P', 'P'): 416,\n",
       "             ('P', 'R'): 4,\n",
       "             ('P', 'T'): 5,\n",
       "             ('P', 'V'): 1,\n",
       "             ('R', '!'): 2,\n",
       "             ('R', 'A'): 21,\n",
       "             ('R', 'D'): 4,\n",
       "             ('R', 'N'): 9,\n",
       "             ('R', 'P'): 9,\n",
       "             ('R', 'R'): 152,\n",
       "             ('R', 'S'): 1,\n",
       "             ('R', 'T'): 2,\n",
       "             ('R', 'V'): 4,\n",
       "             ('R', '^'): 5,\n",
       "             ('S', 'N'): 1,\n",
       "             ('S', 'S'): 2,\n",
       "             ('S', 'V'): 1,\n",
       "             ('S', 'Z'): 1,\n",
       "             ('T', '!'): 1,\n",
       "             ('T', 'O'): 1,\n",
       "             ('T', 'P'): 6,\n",
       "             ('T', 'R'): 1,\n",
       "             ('T', 'T'): 27,\n",
       "             ('U', ','): 1,\n",
       "             ('U', 'N'): 1,\n",
       "             ('U', 'U'): 87,\n",
       "             ('U', 'V'): 2,\n",
       "             ('V', '!'): 4,\n",
       "             ('V', '#'): 1,\n",
       "             ('V', 'A'): 16,\n",
       "             ('V', 'D'): 1,\n",
       "             ('V', 'G'): 1,\n",
       "             ('V', 'N'): 35,\n",
       "             ('V', 'O'): 1,\n",
       "             ('V', 'P'): 5,\n",
       "             ('V', 'R'): 4,\n",
       "             ('V', 'U'): 1,\n",
       "             ('V', 'V'): 656,\n",
       "             ('V', 'X'): 1,\n",
       "             ('V', '^'): 22,\n",
       "             ('V', '~'): 3,\n",
       "             ('X', 'D'): 1,\n",
       "             ('X', 'O'): 1,\n",
       "             ('X', 'R'): 1,\n",
       "             ('X', 'X'): 1,\n",
       "             ('Z', 'N'): 2,\n",
       "             ('Z', 'Z'): 5,\n",
       "             ('Z', '^'): 2,\n",
       "             ('^', '!'): 8,\n",
       "             ('^', '#'): 4,\n",
       "             ('^', '$'): 4,\n",
       "             ('^', '&'): 1,\n",
       "             ('^', 'A'): 9,\n",
       "             ('^', 'D'): 1,\n",
       "             ('^', 'E'): 2,\n",
       "             ('^', 'G'): 2,\n",
       "             ('^', 'L'): 3,\n",
       "             ('^', 'N'): 68,\n",
       "             ('^', 'O'): 2,\n",
       "             ('^', 'P'): 3,\n",
       "             ('^', 'S'): 2,\n",
       "             ('^', 'V'): 22,\n",
       "             ('^', '^'): 178,\n",
       "             ('^', '~'): 2,\n",
       "             ('~', ','): 21,\n",
       "             ('~', '~'): 149})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtnlplib.tagger_base.evalTagger(lambda words,alltags : gtnlplib.tagger_base.classifierTagger(words,gtnlplib.features.yourFeatures,w,alltags),'avg_perceptron_custom.response',testfile=devfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Discriminative Structure Prediction #\n",
    "\n",
    "Now you will implement a Structured Perceptron, which is trained to find the optimal *sequence* $\\vec{y} = \\text{arg}\\max_\\vec{y} \\theta^{\\top} \\vec{f}(\\vec{w},\\vec{y})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key difference from the classification-based setting is that we compute features over the entire sequence.\n",
    "\n",
    "**Deliverable 2a** (1 point): Implement a function seqFeatures in gtnlplib/features.py , which takes a list of words, a list of tags, and a feature function, and returns a dictionary of features and their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.features' from 'gtnlplib/features.pyc'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('**OFFSET**', '--END--'): 1.0,\n",
       "             ('**OFFSET**', 'N'): 2.0,\n",
       "             ('**OFFSET**', 'V'): 2.0,\n",
       "             ('--EMISSION--', 'N', 'fish'): 1.0,\n",
       "             ('--EMISSION--', 'N', 'they'): 1.0,\n",
       "             ('--EMISSION--', 'V', 'can'): 2.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.features)\n",
    "gtnlplib.features.seqFeatures(sent,['N','V','V','N'],wordFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2b** (1 point): now complete the function wordTransFeatures in gtnlplib/features.py, which adds tag-to-tag transition features to wordFeatures. Note that this feature set is identical to what the HMM uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float,\n",
       "            {('**OFFSET**', '--END--'): 1.0,\n",
       "             ('**OFFSET**', 'N'): 2.0,\n",
       "             ('**OFFSET**', 'V'): 2.0,\n",
       "             ('--EMISSION--', 'N', 'fish'): 1.0,\n",
       "             ('--EMISSION--', 'N', 'they'): 1.0,\n",
       "             ('--EMISSION--', 'V', 'can'): 2.0,\n",
       "             ('--TRANS--', '--END--', 'N'): 1.0,\n",
       "             ('--TRANS--', 'N', '--START--'): 1.0,\n",
       "             ('--TRANS--', 'N', 'V'): 1.0,\n",
       "             ('--TRANS--', 'V', 'N'): 1.0,\n",
       "             ('--TRANS--', 'V', 'V'): 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.features)\n",
    "gtnlplib.features.seqFeatures(sent,['N','V','V','N'],gtnlplib.features.wordTransFeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2c** (1 point): copy in your viterbiTagger from problem set 3. If you implemented it correctly, you should be able to use it without modification here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.viterbi' from 'gtnlplib/viterbi.pyc'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.viterbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['N', 'V', 'V', 'N'], 8.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.viterbi)\n",
    "gtnlplib.viterbi.viterbiTagger(['they','can','can','fish'],gtnlplib.features.wordTransFeatures,test_weights,alltags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2d** (3 points): Complete the function oneItAvgStructPerceptron in gtnlplib/str_perceptron.py, which performs a single iteration of averaged structured perceptron. It should be similar to your oneItAvgPerceptron, but will have to be different in some ways to reflect the structured prediction scenario.\n",
    "\n",
    "- To make predictions, you must call your viterbiTagger function\n",
    "- To compute the features for a given sequence of words and tags, you must call your seqFeatures function\n",
    "- As above, output the training accuracy, not the number of training errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.str_perceptron' from 'gtnlplib/str_perceptron.pyc'>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.str_perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed is important here. Use this line to benchmark your code.\n",
    "- My \"optimized\" implementation takes 1.1 seconds per iteration. \n",
    "- My \"less optimized\" implementation takes 1.6 seconds per iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 3: 2 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "reload(gtnlplib.str_perceptron)\n",
    "weights,wsum,tr_acc,i = gtnlplib.str_perceptron.oneItAvgStructPerceptron(tr_all[:100],\n",
    "                                                                         gtnlplib.features.wordTransFeatures,\n",
    "                                                                         defaultdict(float),\n",
    "                                                                         defaultdict(float),\n",
    "                                                                         alltags)\n",
    "# careful, the %%timeit magic means that this block doesn't change the notebook state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.str_perceptron)\n",
    "reload(gtnlplib.viterbi)\n",
    "weights,wsum,tr_acc,i = gtnlplib.str_perceptron.oneItAvgStructPerceptron(tr_all[:100],gtnlplib.features.wordTransFeatures,defaultdict(float),defaultdict(float),alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "! ! -29.0 18.0\n",
      "! , 2.0 -49.0\n",
      "! @ 5.0 -75.0\n",
      "# # -3.0 -130.0\n",
      "# , -3.0 -329.0\n",
      "$ $ -14.0 -194.0\n",
      "$ , 1.0 -164.0\n",
      "& @ 2.0 127.0\n",
      ", ! 3.0 -196.0\n",
      ", # -4.0 -393.0\n",
      ", $ 3.0 68.0\n",
      ", & -3.0 -150.0\n",
      ", , -1.0 -43.0\n",
      ", A 3.0 158.0\n",
      ", @ 1.0 43.0\n",
      "A ! 2.0 108.0\n",
      "A , -1.0 -36.0\n",
      "A A -11.0 -400.0\n",
      "A @ -1.0 -33.0\n",
      "@ ! 1.0 95.0\n",
      "@ & 1.0 45.0\n",
      "@ @ -9.0 -412.0\n"
     ]
    }
   ],
   "source": [
    "for tag1 in list(alltags)[:7]:\n",
    "    for tag2 in list(alltags)[:7]:\n",
    "        if weights[gtnlplib.constants.TRANS,tag1,tag2] != 0:\n",
    "            print tag1,tag2,weights[(gtnlplib.constants.TRANS,tag1,tag2)],wsum[gtnlplib.constants.TRANS,tag1,tag2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2e** (2 points): Implement trainAvgStructPerceptron in gtnlplib/str_perceptron.py. This will be quite similar to your trainAvgPerceptron from ps2, but will have to take slightly different arguments to handle the structured prediction case. Don't forget to use evalTagger to produce output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.373833713456 train: 0.207874015748\n",
      "1 dev: 0.428778768401 train: 0.363779527559\n",
      "2 dev: 0.472527472527 train: 0.587401574803\n",
      "3 dev: 0.494920174165 train: 0.749606299213\n",
      "4 dev: 0.513580758864 train: 0.763779527559\n"
     ]
    }
   ],
   "source": [
    "# your code should roughly reproduce this sanity check. It may be a little slow, so we'll just test on the first 50 instances.\n",
    "# While you're debugging your code, you can run on even smaller datasets.\n",
    "reload(gtnlplib.str_perceptron)\n",
    "theta,tr_acc,dv_acc = gtnlplib.str_perceptron.trainAvgStructPerceptron(5,tr_all[:50],gtnlplib.features.wordTransFeatures,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.66369479577 train: 0.488542307955\n",
      "1 dev: 0.699979266017 train: 0.665366988166\n",
      "2 dev: 0.717395811735 train: 0.742253232095\n",
      "3 dev: 0.730250881194 train: 0.806484711677\n",
      "4 dev: 0.741861911673 train: 0.849716122854\n",
      "5 dev: 0.744764669293 train: 0.874820439155\n",
      "6 dev: 0.748496786233 train: 0.893015938163\n",
      "7 dev: 0.750155504872 train: 0.905055065326\n",
      "8 dev: 0.752850922662 train: 0.914700047883\n",
      "9 dev: 0.754924320962 train: 0.920445994938\n"
     ]
    }
   ],
   "source": [
    "theta,tr_acc,dv_acc = gtnlplib.str_perceptron.trainAvgStructPerceptron(10,tr_all,gtnlplib.features.wordTransFeatures,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "confusion = gtnlplib.tagger_base.evalTagger(lambda words, alltags : gtnlplib.viterbi.viterbiTagger(words,gtnlplib.features.wordTransFeatures,theta,alltags)[0],'str_avg_perceptron.response',testfile=devfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2f** (3 points): Implement a better feature set for structured prediction by completing yourHMMFeatures function in gtnlplib/features.py. For speed reasons, you might not want to use all the features you used in 4e, but try to get as good an accuracy as you can. Last year I was able to get my structured perceptron to work a little better than my best classifier, but this year my classifier is (very slightly) better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'gtnlplib.features' from 'gtnlplib/features.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(gtnlplib.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dev: 0.788720713249 train: 0.657363704768\n",
      "1 dev: 0.819407008086 train: 0.815582461181\n",
      "2 dev: 0.831640058055 train: 0.86059237978\n",
      "3 dev: 0.836823553805 train: 0.887475203502\n",
      "4 dev: 0.840555670744 train: 0.902524112456\n",
      "5 dev: 0.844495127514 train: 0.919146316438\n",
      "6 dev: 0.848019904624 train: 0.927218003967\n",
      "7 dev: 0.847812564794 train: 0.932279909707\n",
      "8 dev: 0.848641924114 train: 0.936110541077\n",
      "9 dev: 0.849056603774 train: 0.942472125316\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.features)\n",
    "theta,tr_acc,dv_acc = gtnlplib.str_perceptron.trainAvgStructPerceptron(10,tr_all,gtnlplib.features.yourHMMFeatures,alltags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849056603774\n"
     ]
    }
   ],
   "source": [
    "reload(gtnlplib.tagger_base)\n",
    "confusion = gtnlplib.tagger_base.evalTagger(lambda words, alltags : gtnlplib.viterbi.viterbiTagger(words,gtnlplib.features.yourHMMFeatures,theta,alltags)[0],'str_avg_perceptron_custom.response',testfile=devfile)\n",
    "print gtnlplib.scorer.accuracy(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A', 'N') 38\n",
      "('V', 'N') 43\n",
      "('N', '^') 37\n",
      "('A', 'V') 23\n",
      "('^', 'V') 24\n",
      "('N', 'V') 39\n",
      "('^', 'N') 56\n",
      "P V 2.25685685686\n",
      "P N 0.237337337337\n",
      "P ^ 4.82752752753\n",
      "N N 1.7963963964\n",
      "395043\n",
      "['Life', 'is', 'like', 'photography', ',', 'we', 'use', 'the', 'negatives', 'to', 'develop', '.']\n",
      "['!', 'V', 'P', 'N', ',', 'O', 'V', 'D', 'N', 'P', 'N', ',']\n",
      "\n",
      "['New', 'Question', ':', 'How', 'CAN', 'you', 'mend', 'a', 'broken', 'heart', '?', 'Really', '?', 'Please', '?:']\n",
      "['A', 'N', ',', 'R', 'V', 'O', 'V', 'D', 'N', 'V', ',', 'R', ',', 'V', ',']\n",
      "\n",
      "['Jay-Z', 'Responds', 'To', 'Beyonce', 'Pregnancy', 'Rumors', '|', 'The', 'Urban', 'Daily', 'http://bit.ly/aMjMsZ']\n",
      "['^', 'N', 'P', '^', 'N', 'N', 'G', 'D', '^', '^', 'U']\n"
     ]
    }
   ],
   "source": [
    "# Cell for debugging\n",
    "for key, value in confusion.iteritems():\n",
    "    if value > 20 and key[0] != key[1]:\n",
    "        print key, value\n",
    "print 'P V', theta.get(('--TRANS--', 'V', 'P'), 0)\n",
    "print 'P N', theta.get(('--TRANS--', 'N', 'P'), 0)\n",
    "print 'P ^', theta.get(('--TRANS--', '^', 'P'), 0)\n",
    "print 'N N', theta.get(('--TRANS--', 'N', 'N'), 0)\n",
    "print len(theta)\n",
    "\n",
    "\n",
    "sent ='Life is like photography , we use the negatives to develop .'.split()\n",
    "print sent\n",
    "print gtnlplib.tagger_base.classifierTagger(sent,gtnlplib.features.yourHMMFeatures, theta, alltags)\n",
    "\n",
    "sent = 'New Question : How CAN you mend a broken heart ? Really ? Please ?:'.split()\n",
    "print\n",
    "print sent\n",
    "print gtnlplib.tagger_base.classifierTagger(sent,gtnlplib.features.yourHMMFeatures, theta, alltags)\n",
    "\n",
    "\n",
    "sent = 'Jay-Z Responds To Beyonce Pregnancy Rumors | The Urban Daily http://bit.ly/aMjMsZ'.split()\n",
    "print\n",
    "print sent\n",
    "print gtnlplib.tagger_base.classifierTagger(sent,gtnlplib.features.yourHMMFeatures, theta, alltags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Error analysis #\n",
    "\n",
    "(3 points; 7650 only). The scorer.py script produces a confusion matrix, which shows the most common types of errors. Consider your best tagger in any part of the assignment, and identify the three most frequent errors (e.g., N classified as V). Find an example sentence in your tagger has made each type of error, and explain why you think it made the mistake, and how it could be fixed. (If you are feeling competitive, you can then use this information to go back and try to improve your features.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the error analysis I am working with my discriminative structured predictions. \n",
    "1. (^, N): 68 and (N,^): 33. The classifier is confused with Nouns and Proper nouns.  \n",
    "     - Example Sentence: In the example sentence, Beyonce has been \"classified\" as Noun.\n",
    "     \n",
    "        Jay-Z Responds To Beyonce Pregnancy Rumors | The Urban Daily http://bit.ly/aMjMsZ   \n",
    "     - Why you think it made the mistake? It made the mistake because it cannot I haven't included any features in the classifier that distinguish proper nouns from nouns. For instance, we could have we have a high probability of having the following tag sequence ^ V | N V or P ^ | P N\n",
    "     - How to fix it? Like Entity Name Recognition, we can add a capitalization features in our feature set. We could detect if the first letter is capitalized and trigger a boolean flag. We also could identify the most common name, and proper name in the datasets and have it as a features. Second approach will be more prone to overfitting the datasets.  \n",
    "     - Results? I tried both approches with only a small improvement.\n",
    "2. (V, N): 42 and (N, V): 44. Here, the classifier was confused with classifying N as Verbs as well as Verbs like N. \n",
    "     - Example Sentence? In the exaample sentence develop has been classified as Noun.\n",
    "   \n",
    "        Life is like photography , we use the negatives to develop .\n",
    "     - Why you think it made the mistake? It made the mistake because P V or P A were very likely. More over, grammar were not very enforced in the twitter datasets. For instance, we also found examples with ungrammatical sentence where V where misclassified. \n",
    "     - How to fix it? We can try to add a trigram features to differencing P D N with P V.   \n",
    "3. (A, N): 36. \n",
    "     - Example Sentence? In the example sentence \"broken\" is classified as noun.\n",
    "\n",
    "        How CAN you mend a broken heart ? Really ? Please ?: http://bit.ly/9RgG9L\n",
    "         \n",
    "     - Why you think it made the mistake? Having D N is highly probable as D A. \n",
    "     - How to fix it? To fix the mistakes we use morphological syntax of english. We can capture english, for instance Adjectives are usually formed with affixes such as -able, -en, -un ... We can also add trigram features to capture D A N and differentiate with N N only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A N 40\n",
      "V N 37\n",
      "N ^ 40\n",
      "^ N 60\n",
      "A V 25\n",
      "^ V 22\n",
      "N V 51\n"
     ]
    }
   ],
   "source": [
    "for (true, pred), value in confusion.iteritems():\n",
    "    if true != pred and value > 20:\n",
    "        print true, pred, value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Bakeoff! #\n",
    "\n",
    "48 hours before the assignment is due, we will send you unlabeled test data. Your job is to produce a response file that I can evaluate. I'll present the results in class and give the best scorers a chance to explain what they did.\n",
    "\n",
    "\n",
    "** Deliverable 4 ** (3 points) Run your best system from any part of the\n",
    "assignment on the test data using the `generateKaggleSubmission()` function. Submit\n",
    "your response file to the class [Kaggle bakeoff](https://inclass.kaggle.com/c/gt-book-review-sentiment-analysis). Also **submit your Kaggle response file to T-Square as 'lastname-firstname.response'.** The top\n",
    "scores will be announced in class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtnlplib.clf_base)\n",
    "reload(gtnlplib.preproc)\n",
    "confusion = gtnlplib.tagger_base.evalTagger(lambda words, alltags : gtnlplib.viterbi.viterbiTagger(words,gtnlplib.features.yourHMMFeatures,theta,alltags)[0],'andrianarimanana-harinando.response',testfile=testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gtnlplib.clf_base.generateKaggleSubmission(lambda words,alltags : gtnlplib.viterbi.viterbiTagger(words,gtnlplib.features.yourHMMFeatures,theta,alltags),'andrianarimanana-harinando-84-49.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
